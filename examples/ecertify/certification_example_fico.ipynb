{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "055595df",
   "metadata": {},
   "source": [
    "# End to end example on certifying local explanations using `Ecertify`\n",
    "\n",
    "In this notebook, we demonstrate how to _certify_ a local explanation for a prediction of a classification \n",
    "model. Here we choose the popular tabular dataset [FICO HELOC](https://github.com/Trusted-AI/AIX360/blob/master/examples/tutorials/HELOC.ipynb), and use local explainers such as [LIME](https://github.com/marcotcr/lime) and [SHAP](https://github.com/shap/shap) for certification. We also comment\n",
    "on how the explainers can be compared on the basis of their (found) certification widths ($w$) at the end.\n",
    "The cells below describe steps needed to perform certification in detail:\n",
    "\n",
    "1. obtaining a trained model on the dataset, here we use `GradientBoostingClassifier` from the sklearn library\n",
    "2. selecting an instance of interest and computing its explanation\n",
    "3. defining the quality criterion (here we use `1 - mean absolute error`, i.e., the fidelity as mentioned in the paper) to assess the degree to which the computed explanation is _applicable_ to other instances\n",
    "4. decide the fidelity threshold $\\theta$, this is another user configurable option\n",
    "5. certify the explanation, i.e., find the largest hypercube around the original instance where the computed explanation has sufficiently high fidelity $\\ge \\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fc93a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys; sys.path.append('../../aix360/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93f69b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os, math, timeit, pickle\n",
    "from datetime import datetime\n",
    "import numpy as np; np.set_printoptions(suppress=True)\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# sklearn utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, r2_score\n",
    "\n",
    "\n",
    "# explainers\n",
    "import shap, lime\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "\n",
    "# our code\n",
    "from aix360.algorithms.ecertify.utils import load_fico_dataset, compute_lime_explainer, compute_shap_explainer\n",
    "# from algorithms.ecertify.utils import load_fico_dataset, compute_lime_explainer, compute_shap_explainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea52e04",
   "metadata": {},
   "source": [
    "## Load dataset and prepare the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d78ffec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 85.03%\n",
      "test accuracy: 82.55%\n"
     ]
    }
   ],
   "source": [
    "random_state=1234\n",
    "\n",
    "# load FICO data and split into train-test sets\n",
    "df, y = load_fico_dataset(path='./data/heloc-clean-full.csv')\n",
    "x_train, x_test, y_train, y_test = train_test_split(df, y, train_size=0.7, random_state=random_state)\n",
    "is_regression = False # this is a classification dataset\n",
    "\n",
    "# standardization\n",
    "EXtr, StdXtr = x_train.mean(0), x_train.std(0)\n",
    "x_train = (x_train - EXtr) / StdXtr\n",
    "x_test = (x_test - EXtr) / StdXtr\n",
    "\n",
    "\n",
    "# fit a gradient boosted classifier on this dataset\n",
    "model = GradientBoostingClassifier(random_state=random_state)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# check accuracy\n",
    "print(f\"train accuracy: {np.around(accuracy_score(y_train, model.predict(x_train)), 4) * 100}%\")\n",
    "print(f\"test accuracy: {np.around(accuracy_score(y_test, model.predict(x_test)), 4) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a8cb86",
   "metadata": {},
   "source": [
    "## Prepare the callables for querying the model and the explanation during certification\n",
    "The next cell prepares few callables: `_bb()` and `_e()` to query the `model` and the explanation. Note that\n",
    "we are assuming we have obtained a functional form of the computed explainer which can be _applied_ to another\n",
    "instance. In case of LIME, the explanation is a linear function with weights/coefficients set as the feature\n",
    "importance values in the explanation. For KernelSHAP, a similar linear function is used as well. We apply the\n",
    "function on an instance and get the correct class' (the original instance's class for which the explanation \n",
    "was computed) probability.\n",
    "\n",
    "Later when we have the `model` and the `expl_func` ready, we can wrap these functions(`_bb()` and `_e()`) with\n",
    "the `partial` _functool_ to hide the second argument (e.g., `expl_func` in `_e()`) and only pass the first argument `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dba4d6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def _bb(x, model, label_x0=0, is_regression=False):\n",
    "    \"\"\"\n",
    "        x: single 1d numpy array of shape (d, )\n",
    "        label_x0: if classification, we need to take the correct class' probability\n",
    "    \"\"\"\n",
    "    x = [x]\n",
    "\n",
    "    if is_regression:\n",
    "        return model.predict(x)[0]\n",
    "    else:\n",
    "        return model.predict_proba(x)[:, label_x0][0]\n",
    "\n",
    "\n",
    "def _e(x, expl_func):\n",
    "    \"\"\"\n",
    "        x: single 1d numpy array of shape (d, )\n",
    "        expl_func: a callable/sklearn model with predict method\n",
    "    \"\"\"\n",
    "\n",
    "    x = [x]\n",
    "    return expl_func.predict(x)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fe7c55",
   "metadata": {},
   "source": [
    "## Choose a random sample for finding explanation and certification\n",
    "Here we choose one prototype that we also discussed in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c1cbae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data index=6863\n",
      "model class probs output: [0.8918 0.1082], ground truth label: 0.0\n",
      "predicted prob: 0.8918, predicted label: 0\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 6863\n",
    "\n",
    "x0 = x_train.iloc[sample_idx]\n",
    "true_label = y_train.iloc[sample_idx]\n",
    "\n",
    "# Get the output of the black-box classifier on x0\n",
    "output = model.predict_proba([x0])[0]\n",
    "label_x0 = np.argmax(output)\n",
    "prob_x0 = output[label_x0]\n",
    "\n",
    "print(f'data index={sample_idx}')\n",
    "print(f\"model class probs output: {np.around(output, 4)}, ground truth label: {true_label}\")\n",
    "print(f'predicted prob: {prob_x0:.4f}, predicted label: {label_x0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f832a6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>8165</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ExternalRiskEstimate</th>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSinceOldestTradeOpen</th>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSinceMostRecentTradeOpen</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AverageMInFile</th>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumSatisfactoryTrades</th>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumTrades60Ever2DerogPubRec</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumTrades90Ever2DerogPubRec</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PercentTradesNeverDelq</th>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSinceMostRecentDelq</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxDelq2PublicRecLast12M</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaxDelqEver</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumTotalTrades</th>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumTradesOpeninLast12M</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PercentInstallTrades</th>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSinceMostRecentInqexcl7days</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumInqLast6M</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumInqLast6Mexcl7days</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NetFractionRevolvingBurden</th>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NetFractionInstallBurden</th>\n",
       "      <td>471.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumRevolvingTradesWBalance</th>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumInstallTradesWBalance</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumBank2NatlTradesWHighUtilization</th>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PercentTradesWBalance</th>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     8165\n",
       "ExternalRiskEstimate                 49.0\n",
       "MSinceOldestTradeOpen               200.0\n",
       "MSinceMostRecentTradeOpen             2.0\n",
       "AverageMInFile                       71.0\n",
       "NumSatisfactoryTrades                45.0\n",
       "NumTrades60Ever2DerogPubRec           0.0\n",
       "NumTrades90Ever2DerogPubRec           0.0\n",
       "PercentTradesNeverDelq               98.0\n",
       "MSinceMostRecentDelq                  4.0\n",
       "MaxDelq2PublicRecLast12M              4.0\n",
       "MaxDelqEver                           6.0\n",
       "NumTotalTrades                       48.0\n",
       "NumTradesOpeninLast12M                3.0\n",
       "PercentInstallTrades                 22.0\n",
       "MSinceMostRecentInqexcl7days         24.0\n",
       "NumInqLast6M                          1.0\n",
       "NumInqLast6Mexcl7days                 1.0\n",
       "NetFractionRevolvingBurden           86.0\n",
       "NetFractionInstallBurden            471.0\n",
       "NumRevolvingTradesWBalance           19.0\n",
       "NumInstallTradesWBalance              2.0\n",
       "NumBank2NatlTradesWHighUtilization    9.0\n",
       "PercentTradesWBalance                81.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the instance x0\n",
    "(x_train.iloc[sample_idx:sample_idx+1] * StdXtr + EXtr).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5ab5b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the blackbox function for querying the model, partial magic\n",
    "bb = partial(_bb, model=model, label_x0=label_x0, is_regression=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a7f31",
   "metadata": {},
   "source": [
    "## Check fidelity of explanations on the point `x0` itself\n",
    "\n",
    "Note that LIME explanations can have fidelity less than 1.0 on that instance, i.e., the linear/affine function \n",
    "approximated the model at $x_0$ need not pass through the model's predicted probability for $x_0$. But for \n",
    "KernelSHAP, the approximating linear function always passes through model's predicted probability (this is\n",
    "also known as the efficiency criterion for shapley values, i.e., the sum of values should be equal to the \n",
    "total value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1af94b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test lime: \n",
      "bb(x)=0.8918, e(x)=0.7679\n",
      "fidelity at x0: f(x)=0.8761\n",
      "----------------------------------------\n",
      "test shap: \n",
      "bb(x)=0.8918, e(x)=0.8918\n",
      "fidelity at x0: f(x)=1.0000\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"test lime: \")\n",
    "# test the function from utilities\n",
    "func, expl = compute_lime_explainer(x_train, model, x0, num_features=len(x0))\n",
    "e = partial(_e, expl_func=func)\n",
    "f = lambda x: 1 - abs(bb(x) - e(x))  # fidelity function (specific to this explanation)\n",
    "\n",
    "print(f\"bb(x)={bb(x0.values):.4f}, e(x)={e(x0.values):.4f}\")\n",
    "print(f\"fidelity at x0: f(x)={f(x0.values):.4f}\")\n",
    "print('-'*40)\n",
    "\n",
    "\n",
    "\n",
    "print(\"test shap: \")\n",
    "\n",
    "func, expl = compute_shap_explainer(x_train, model, x0)\n",
    "e = partial(_e, expl_func=func)\n",
    "f = lambda x: 1 - abs(bb(x) - e(x))  # fidelity function (specific to this explanation)\n",
    "\n",
    "print(f\"bb(x)={bb(x0.values):.4f}, e(x)={e(x0.values):.4f}\")\n",
    "print(f\"fidelity at x0: f(x)={f(x0.values):.4f}\")\n",
    "\n",
    "print('-'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9b242e",
   "metadata": {},
   "source": [
    "# Certification\n",
    "For this step, we would need callables $bb(.)$, $e(.)$ and $f(.)$ that we prepared earlier. Note that the \n",
    "algorithm only requires the user to define a suitable fidelity function $f(.)$ that subsumes the calls to the \n",
    "blackbox model, $bb(.)$, and the local explanation function, $e(.)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f63775d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aix360.algorithms.ecertify.ecertify import CertifyExplanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba1e370",
   "metadata": {},
   "source": [
    "First we certify for the LIME explanation, we are computing again since in the last cell the variables were\n",
    "overwritten by the SHAP explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1940a4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "func, expl = compute_lime_explainer(x_train, model, x0, num_features=len(x0))\n",
    "e = partial(_e, expl_func=func)\n",
    "f = lambda x: 1 - abs(bb(x) - e(x))  # fidelity function (specific to this explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbf8aa9",
   "metadata": {},
   "source": [
    "## Initialize the certifier object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47bc1168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs to Certify()\n",
    "theta = 0.75   # user desired fidelity threshold                                     \n",
    "lb = 0; ub = 1 # init hypercube of size 1\n",
    "Q = 10000      # query budget related arguments\n",
    "Z = 10         # number of halving/doubling iterations during certification (so total queries expensed = Z*Q)\n",
    "sigma0 = 0.1   # sigma for gaussians used in unifI and adaptI strategies\n",
    "NUMRUNS = 10   # consider running for more iterations here for reduced error\n",
    "\n",
    "certifier = CertifyExplanation(theta=theta, Q=Q, Z=Z, lb=lb, ub=ub, sigma0=sigma0, numruns=NUMRUNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4d988077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time per run: 6.844 s\n",
      "Found w: 0.4298 ± 0.047384\n"
     ]
    }
   ],
   "source": [
    "x = x0.values\n",
    "s = 3\n",
    "\n",
    "w = certifier.certify_instance(instance=x, quality_criterion=f, strategy=s, silent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371fcc86",
   "metadata": {},
   "source": [
    "## Certification of SHAP\n",
    "Similarly we could also certify the KernelSHAP explanation for the same instance, just using a properly defined quality criterion that takes the SHAP `expl_func` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd418d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the KernelSHAP explanation\n",
    "func, expl = compute_shap_explainer(x_train, model, x0)\n",
    "e = partial(_e, expl_func=func)\n",
    "f = lambda x: 1 - abs(bb(x) - e(x))  # fidelity function (specific to this explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a7dfbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time per run: 4.467 s\n",
      "Found w: 0.0272 ± 0.002681\n"
     ]
    }
   ],
   "source": [
    "x = x0.values\n",
    "s = 3\n",
    "\n",
    "w = certifier.certify_instance(instance=x, quality_criterion=f, strategy=s, silent=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602edc80",
   "metadata": {},
   "source": [
    "## Observation\n",
    "Note that for this instance, the LIME explanation has a larger certifier width ($\\approx 0.3-0.4$) than the \n",
    "KernelSHAP explanation ($\\approx 0.02-0.04$), implying the linear explanation obtained from LIME is applicable \n",
    "to a relatively large neighbourhood than the corresponding KernelSHAP explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a806c92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37b7226",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
